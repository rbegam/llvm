; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; REQUIRES: intel_feature_isa_fp16
; RUN: llc < %s -mtriple=x86_64-unknown-unknown -mattr=+avx512fp16 | FileCheck %s

define <8 x half> @broadcastph128(half* %x) {
; CHECK-LABEL: broadcastph128:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpbroadcastw (%rdi), %xmm0
; CHECK-NEXT:    retq
  %l1 = load half, half* %x, align 2
  %vec = insertelement <8 x half> undef, half %l1, i32 0
  %res = shufflevector <8 x half> %vec, <8 x half> undef, <8 x i32> zeroinitializer
  ret <8 x half> %res
}

define <16 x half> @broadcastph256(half* %x) {
; CHECK-LABEL: broadcastph256:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpbroadcastw (%rdi), %ymm0
; CHECK-NEXT:    retq
  %l1 = load half, half* %x, align 2
  %vec = insertelement <16 x half> undef, half %l1, i32 0
  %res = shufflevector <16 x half> %vec, <16 x half> undef, <16 x i32> zeroinitializer
  ret <16 x half> %res
}

define <32 x half> @broadcastph512(half* %x) {
; CHECK-LABEL: broadcastph512:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpbroadcastw (%rdi), %zmm0
; CHECK-NEXT:    retq
  %l1 = load half, half* %x, align 2
  %vec = insertelement <32 x half> undef, half %l1, i32 0
  %res = shufflevector <32 x half> %vec, <32 x half> undef, <32 x i32> zeroinitializer
  ret <32 x half> %res
}

define void @test5(half %x, half* %y) {
; CHECK-LABEL: test5:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovsh %xmm0, (%rdi)
; CHECK-NEXT:    retq
   store half %x, half* %y, align 2
   ret void
}

define half @test7(i16* %x) {
; CHECK-LABEL: test7:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovsh (%rdi), %xmm0
; CHECK-NEXT:    retq
   %y = load i16, i16* %x
   %res = bitcast i16 %y to half
   ret half %res
}

define <8 x i16> @test10(i16* %x) {
; CHECK-LABEL: test10:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovw (%rdi), %xmm0
; CHECK-NEXT:    retq
   %y = load i16, i16* %x, align 2
   %res = insertelement <8 x i16>zeroinitializer, i16 %y, i32 0
   ret <8 x i16>%res
}

define <8 x half> @test11(half* %x) {
; CHECK-LABEL: test11:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovsh (%rdi), %xmm0
; CHECK-NEXT:    retq
   %y = load half, half* %x, align 2
   %res = insertelement <8 x half>zeroinitializer, half %y, i32 0
   ret <8 x half>%res
}

define <8 x i16> @test15(i16 %x) {
; CHECK-LABEL: test15:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovw %edi, %xmm0
; CHECK-NEXT:    retq
   %res = insertelement <8 x i16>zeroinitializer, i16 %x, i32 0
   ret <8 x i16>%res
}

@g8f16 = external global <8 x half>
@g8f16u = external global <8 x half>, align 8
@g16f16 = external global <16 x half>
@g16f16u = external global <16 x half>, align 8
@g32f16 = external global <32 x half>
@g32f16u = external global <32 x half>, align 8

define <32 x half> @load32f16(<32 x half>* %a) {
; CHECK-LABEL: load32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps (%rdi), %zmm0
; CHECK-NEXT:    retq
  %res = load <32 x half>, <32 x half>* %a
  ret <32 x half> %res
}

define <32 x half> @load32f16mask(<32 x half>* %a, <32 x half> %b, i32 %c) {
; CHECK-LABEL: load32f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x half>, <32 x half>* %a
  %res = select <32 x i1> %msk, <32 x half> %res0, <32 x half> %b
  ret <32 x half> %res
}

define <32 x half> @load32f16maskz(<32 x half>* %a, i32 %c) {
; CHECK-LABEL: load32f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x half>, <32 x half>* %a
  %res = select <32 x i1> %msk, <32 x half> %res0, <32 x half> zeroinitializer
  ret <32 x half> %res
}

define <32 x half> @loadu32f16(<32 x half>* %a) {
; CHECK-LABEL: loadu32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups (%rdi), %zmm0
; CHECK-NEXT:    retq
  %res = load <32 x half>, <32 x half>* %a, align 8
  ret <32 x half> %res
}

define <32 x half> @loadu32f16mask(<32 x half>* %a, <32 x half> %b, i32 %c) {
; CHECK-LABEL: loadu32f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x half>, <32 x half>* %a, align 8
  %res = select <32 x i1> %msk, <32 x half> %res0, <32 x half> %b
  ret <32 x half> %res
}

define <32 x half> @loadu32f16maskz(<32 x half>* %a, i32 %c) {
; CHECK-LABEL: loadu32f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i32 %c to <32 x i1>
  %res0 = load <32 x half>, <32 x half>* %a, align 8
  %res = select <32 x i1> %msk, <32 x half> %res0, <32 x half> zeroinitializer
  ret <32 x half> %res
}

define void @store32f16(<32 x half> %a) {
; CHECK-LABEL: store32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %zmm0, {{.*}}(%rip)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  store <32 x half> %a, <32 x half>* @g32f16
  ret void
}

define void @storeu32f16(<32 x half> %a) {
; CHECK-LABEL: storeu32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups %zmm0, {{.*}}(%rip)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  store <32 x half> %a, <32 x half>* @g32f16u, align 8
  ret void
}

declare void @llvm.masked.store.v32f16.p0v32f16(<32 x half>, <32 x half>*, i32, <32 x i1>)
declare <32 x half> @llvm.masked.load.v32f16.p0v32f16(<32 x half>*, i32,  <32 x i1>, <32 x half>)

define void @storeu32f16mask(<32 x i1> %mask, <32 x half>* %addr, <32 x half> %val) {
; CHECK-LABEL: storeu32f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %ymm0, %ymm0
; CHECK-NEXT:    vpmovb2m %ymm0, %k1
; CHECK-NEXT:    vmovdqu16 %zmm1, (%rdi) {%k1}
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  call void @llvm.masked.store.v32f16.p0v32f16(<32 x half> %val, <32 x half>* %addr, i32 4, <32 x i1>%mask)
  ret void
}

define <32 x half> @maskloadu32f16(<32 x half>* %addr, <32 x half> %val, <32 x i1> %mask) {
; CHECK-LABEL: maskloadu32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %ymm1, %ymm1
; CHECK-NEXT:    vpmovb2m %ymm1, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1}
; CHECK-NEXT:    retq
  %res = call <32 x half> @llvm.masked.load.v32f16.p0v32f16(<32 x half>* %addr, i32 4, <32 x i1> %mask, <32 x half> %val)
  ret <32 x half> %res
}

define <32 x half> @maskuloadu32f16(<32 x half>* %addr, <32 x i1> %mask) {
; CHECK-LABEL: maskuloadu32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %ymm0, %ymm0
; CHECK-NEXT:    vpmovb2m %ymm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <32 x half> @llvm.masked.load.v32f16.p0v32f16(<32 x half>* %addr, i32 4, <32 x i1> %mask, <32 x half> undef)
  ret <32 x half> %res
}

define <32 x half> @maskzloadu32f16(<32 x half>* %addr, <32 x i1> %mask) {
; CHECK-LABEL: maskzloadu32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %ymm0, %ymm0
; CHECK-NEXT:    vpmovb2m %ymm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %zmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <32 x half> @llvm.masked.load.v32f16.p0v32f16(<32 x half>* %addr, i32 4, <32 x i1> %mask, <32 x half> zeroinitializer)
  ret <32 x half> %res
}

define <32 x half> @movrr32f16(<32 x half> %a, <32 x half> %b) {
; CHECK-LABEL: movrr32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %zmm1, %zmm0
; CHECK-NEXT:    retq
  ret <32 x half> %b
}

define <32 x half> @movrrk32f16(<32 x half> %a, <32 x half> %b, i32 %msk) {
; CHECK-LABEL: movrrk32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vpblendmw %zmm0, %zmm1, %zmm0 {%k1}
; CHECK-NEXT:    retq
  %mask = bitcast i32 %msk to <32 x i1>
  %res = select <32 x i1> %mask, <32 x half> %a, <32 x half> %b
  ret <32 x half> %res
}

define <32 x half> @movrrkz32f16(<32 x half> %a, i32 %msk) {
; CHECK-LABEL: movrrkz32f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vmovdqu16 %zmm0, %zmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %mask = bitcast i32 %msk to <32 x i1>
  %res = select <32 x i1> %mask, <32 x half> %a, <32 x half> zeroinitializer
  ret <32 x half> %res
}

define <16 x half> @load16f16(<16 x half>* %a) {
; CHECK-LABEL: load16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps (%rdi), %ymm0
; CHECK-NEXT:    retq
  %res = load <16 x half>, <16 x half>* %a
  ret <16 x half> %res
}

define <16 x half> @load16f16mask(<16 x half>* %a, <16 x half> %b, i16 %c) {
; CHECK-LABEL: load16f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x half>, <16 x half>* %a
  %res = select <16 x i1> %msk, <16 x half> %res0, <16 x half> %b
  ret <16 x half> %res
}

define <16 x half> @load16f16maskz(<16 x half>* %a, i16 %c) {
; CHECK-LABEL: load16f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x half>, <16 x half>* %a
  %res = select <16 x i1> %msk, <16 x half> %res0, <16 x half> zeroinitializer
  ret <16 x half> %res
}

define <16 x half> @loadu16f16(<16 x half>* %a) {
; CHECK-LABEL: loadu16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups (%rdi), %ymm0
; CHECK-NEXT:    retq
  %res = load <16 x half>, <16 x half>* %a, align 8
  ret <16 x half> %res
}

define <16 x half> @loadu16f16mask(<16 x half>* %a, <16 x half> %b, i16 %c) {
; CHECK-LABEL: loadu16f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x half>, <16 x half>* %a, align 8
  %res = select <16 x i1> %msk, <16 x half> %res0, <16 x half> %b
  ret <16 x half> %res
}

define <16 x half> @loadu16f16maskz(<16 x half>* %a, i16 %c) {
; CHECK-LABEL: loadu16f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i16 %c to <16 x i1>
  %res0 = load <16 x half>, <16 x half>* %a, align 8
  %res = select <16 x i1> %msk, <16 x half> %res0, <16 x half> zeroinitializer
  ret <16 x half> %res
}

define void @store16f16(<16 x half> %a) {
; CHECK-LABEL: store16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %ymm0, {{.*}}(%rip)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  store <16 x half> %a, <16 x half>* @g16f16
  ret void
}

define void @storeu16f16(<16 x half> %a) {
; CHECK-LABEL: storeu16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups %ymm0, {{.*}}(%rip)
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  store <16 x half> %a, <16 x half>* @g16f16u, align 8
  ret void
}

declare void @llvm.masked.store.v16f16.p0v16f16(<16 x half>, <16 x half>*, i32, <16 x i1>)
declare <16 x half> @llvm.masked.load.v16f16.p0v16f16(<16 x half>*, i32,  <16 x i1>, <16 x half>)

define void @storeu16f16mask(<16 x i1> %mask, <16 x half>* %addr, <16 x half> %val) {
; CHECK-LABEL: storeu16f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %xmm0, %xmm0
; CHECK-NEXT:    vpmovb2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 %ymm1, (%rdi) {%k1}
; CHECK-NEXT:    vzeroupper
; CHECK-NEXT:    retq
  call void @llvm.masked.store.v16f16.p0v16f16(<16 x half> %val, <16 x half>* %addr, i32 4, <16 x i1>%mask)
  ret void
}

define <16 x half> @maskloadu16f16(<16 x half>* %addr, <16 x half> %val, <16 x i1> %mask) {
; CHECK-LABEL: maskloadu16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %xmm1, %xmm1
; CHECK-NEXT:    vpmovb2m %xmm1, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1}
; CHECK-NEXT:    retq
  %res = call <16 x half> @llvm.masked.load.v16f16.p0v16f16(<16 x half>* %addr, i32 4, <16 x i1> %mask, <16 x half> %val)
  ret <16 x half> %res
}

define <16 x half> @maskuloadu16f16(<16 x half>* %addr, <16 x i1> %mask) {
; CHECK-LABEL: maskuloadu16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %xmm0, %xmm0
; CHECK-NEXT:    vpmovb2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <16 x half> @llvm.masked.load.v16f16.p0v16f16(<16 x half>* %addr, i32 4, <16 x i1> %mask, <16 x half> undef)
  ret <16 x half> %res
}

define <16 x half> @maskzloadu16f16(<16 x half>* %addr, <16 x i1> %mask) {
; CHECK-LABEL: maskzloadu16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $7, %xmm0, %xmm0
; CHECK-NEXT:    vpmovb2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %ymm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <16 x half> @llvm.masked.load.v16f16.p0v16f16(<16 x half>* %addr, i32 4, <16 x i1> %mask, <16 x half> zeroinitializer)
  ret <16 x half> %res
}

define <16 x half> @movrr16f16(<16 x half> %a, <16 x half> %b) {
; CHECK-LABEL: movrr16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %ymm1, %ymm0
; CHECK-NEXT:    retq
  ret <16 x half> %b
}

define <16 x half> @movrrk16f16(<16 x half> %a, <16 x half> %b, i16 %msk) {
; CHECK-LABEL: movrrk16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vpblendmw %ymm0, %ymm1, %ymm0 {%k1}
; CHECK-NEXT:    retq
  %mask = bitcast i16 %msk to <16 x i1>
  %res = select <16 x i1> %mask, <16 x half> %a, <16 x half> %b
  ret <16 x half> %res
}

define <16 x half> @movrrkz16f16(<16 x half> %a, i16 %msk) {
; CHECK-LABEL: movrrkz16f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vmovdqu16 %ymm0, %ymm0 {%k1} {z}
; CHECK-NEXT:    retq
  %mask = bitcast i16 %msk to <16 x i1>
  %res = select <16 x i1> %mask, <16 x half> %a, <16 x half> zeroinitializer
  ret <16 x half> %res
}

define <8 x half> @load8f16(<8 x half>* %a) {
; CHECK-LABEL: load8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps (%rdi), %xmm0
; CHECK-NEXT:    retq
  %res = load <8 x half>, <8 x half>* %a
  ret <8 x half> %res
}

define <8 x half> @load8f16mask(<8 x half>* %a, <8 x half> %b, i8 %c) {
; CHECK-LABEL: load8f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x half>, <8 x half>* %a
  %res = select <8 x i1> %msk, <8 x half> %res0, <8 x half> %b
  ret <8 x half> %res
}

define <8 x half> @load8f16maskz(<8 x half>* %a, i8 %c) {
; CHECK-LABEL: load8f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x half>, <8 x half>* %a
  %res = select <8 x i1> %msk, <8 x half> %res0, <8 x half> zeroinitializer
  ret <8 x half> %res
}

define <8 x half> @loadu8f16(<8 x half>* %a) {
; CHECK-LABEL: loadu8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups (%rdi), %xmm0
; CHECK-NEXT:    retq
  %res = load <8 x half>, <8 x half>* %a, align 8
  ret <8 x half> %res
}

define <8 x half> @loadu8f16mask(<8 x half>* %a, <8 x half> %b, i8 %c) {
; CHECK-LABEL: loadu8f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; CHECK-NEXT:    retq
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x half>, <8 x half>* %a, align 8
  %res = select <8 x i1> %msk, <8 x half> %res0, <8 x half> %b
  ret <8 x half> %res
}

define <8 x half> @loadu8f16maskz(<8 x half>* %a, i8 %c) {
; CHECK-LABEL: loadu8f16maskz:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %esi, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %msk = bitcast i8 %c to <8 x i1>
  %res0 = load <8 x half>, <8 x half>* %a, align 8
  %res = select <8 x i1> %msk, <8 x half> %res0, <8 x half> zeroinitializer
  ret <8 x half> %res
}

define void @store8f16(<8 x half> %a) {
; CHECK-LABEL: store8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %xmm0, {{.*}}(%rip)
; CHECK-NEXT:    retq
  store <8 x half> %a, <8 x half>* @g8f16
  ret void
}

define void @storeu8f16(<8 x half> %a) {
; CHECK-LABEL: storeu8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovups %xmm0, {{.*}}(%rip)
; CHECK-NEXT:    retq
  store <8 x half> %a, <8 x half>* @g8f16u, align 8
  ret void
}

declare void @llvm.masked.store.v8f16.p0v8f16(<8 x half>, <8 x half>*, i32, <8 x i1>)
declare <8 x half> @llvm.masked.load.v8f16.p0v8f16(<8 x half>*, i32,  <8 x i1>, <8 x half>)

define void @storeu8f16mask(<8 x i1> %mask, <8 x half>* %addr, <8 x half> %val) {
; CHECK-LABEL: storeu8f16mask:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $15, %xmm0, %xmm0
; CHECK-NEXT:    vpmovw2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 %xmm1, (%rdi) {%k1}
; CHECK-NEXT:    retq
  call void @llvm.masked.store.v8f16.p0v8f16(<8 x half> %val, <8 x half>* %addr, i32 4, <8 x i1>%mask)
  ret void
}

define <8 x half> @maskloadu8f16(<8 x half>* %addr, <8 x half> %val, <8 x i1> %mask) {
; CHECK-LABEL: maskloadu8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $15, %xmm1, %xmm1
; CHECK-NEXT:    vpmovw2m %xmm1, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1}
; CHECK-NEXT:    retq
  %res = call <8 x half> @llvm.masked.load.v8f16.p0v8f16(<8 x half>* %addr, i32 4, <8 x i1> %mask, <8 x half> %val)
  ret <8 x half> %res
}

define <8 x half> @maskuloadu8f16(<8 x half>* %addr, <8 x i1> %mask) {
; CHECK-LABEL: maskuloadu8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $15, %xmm0, %xmm0
; CHECK-NEXT:    vpmovw2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <8 x half> @llvm.masked.load.v8f16.p0v8f16(<8 x half>* %addr, i32 4, <8 x i1> %mask, <8 x half> undef)
  ret <8 x half> %res
}

define <8 x half> @maskzloadu8f16(<8 x half>* %addr, <8 x i1> %mask) {
; CHECK-LABEL: maskzloadu8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpsllw $15, %xmm0, %xmm0
; CHECK-NEXT:    vpmovw2m %xmm0, %k1
; CHECK-NEXT:    vmovdqu16 (%rdi), %xmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %res = call <8 x half> @llvm.masked.load.v8f16.p0v8f16(<8 x half>* %addr, i32 4, <8 x i1> %mask, <8 x half> zeroinitializer)
  ret <8 x half> %res
}

define <8 x half> @movrr8f16(<8 x half> %a, <8 x half> %b) {
; CHECK-LABEL: movrr8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovaps %xmm1, %xmm0
; CHECK-NEXT:    retq
  ret <8 x half> %b
}

define <8 x half> @movrrk8f16(<8 x half> %a, <8 x half> %b, i8 %msk) {
; CHECK-LABEL: movrrk8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vpblendmw %xmm0, %xmm1, %xmm0 {%k1}
; CHECK-NEXT:    retq
  %mask = bitcast i8 %msk to <8 x i1>
  %res = select <8 x i1> %mask, <8 x half> %a, <8 x half> %b
  ret <8 x half> %res
}

define <8 x half> @movrrkz8f16(<8 x half> %a, i8 %msk) {
; CHECK-LABEL: movrrkz8f16:
; CHECK:       # %bb.0:
; CHECK-NEXT:    kmovd %edi, %k1
; CHECK-NEXT:    vmovdqu16 %xmm0, %xmm0 {%k1} {z}
; CHECK-NEXT:    retq
  %mask = bitcast i8 %msk to <8 x i1>
  %res = select <8 x i1> %mask, <8 x half> %a, <8 x half> zeroinitializer
  ret <8 x half> %res
}

define <8 x half> @movsh(<8 x half> %a, <8 x half> %b) {
; CHECK-LABEL: movsh:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vpshufb {{.*#+}} xmm2 = xmm0[0,1,14,15,0,1,2,3,4,5,6,7,14,15,10,11]
; CHECK-NEXT:    vmovsh %xmm0, %xmm1, %xmm0
; CHECK-NEXT:    vaddph %xmm0, %xmm2, %xmm0
; CHECK-NEXT:    retq
  %res1 = shufflevector <8 x half> %a, <8 x half> %b, <8 x i32> <i32 0, i32 7, i32 0, i32 1, i32 2, i32 3, i32 7, i32 5>
  %res2 = shufflevector <8 x half> %a, <8 x half> %b, <8 x i32> <i32 0, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15>
  %res = fadd <8 x half> %res1, %res2
  ret <8 x half> %res
}

define i16 @test_movw(half %x) {
; CHECK-LABEL: test_movw:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovw %xmm0, %eax
; CHECK-NEXT:    # kill: def $ax killed $ax killed $eax
; CHECK-NEXT:    retq
  %res = bitcast half %x to i16
  ret i16 %res
}

define half @test_movw2(i16 %x) {
; CHECK-LABEL: test_movw2:
; CHECK:       # %bb.0:
; CHECK-NEXT:    vmovw %edi, %xmm0
; CHECK-NEXT:    retq
  %res = bitcast i16 %x to half
  ret half %res
}
